#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¸å¾®è°ƒåçš„ Qwen1.5-0.5B æ¨¡å‹è¿›è¡Œäº¤äº’å¯¹è¯
æ”¯æŒå¤šè½®å¯¹è¯å’Œè§’è‰²æ‰®æ¼”
"""

import os
import sys
import time
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, StoppingCriteria, StoppingCriteriaList

from termcolor import colored

# =============== é…ç½®åŒºåŸŸ ===============
MODEL_DIR = "./qwen_finetuned"  # æ‚¨ä¿å­˜å¾®è°ƒæ¨¡å‹çš„ç›®å½•
MAX_NEW_TOKENS = 512  # ç”Ÿæˆå›å¤çš„æœ€å¤§é•¿åº¦
TEMPERATURE = 0.7     # åˆ›é€ æ€§ï¼ˆ0.1-1.0ï¼Œå€¼è¶Šå¤§è¶Šæœ‰åˆ›æ„ï¼‰
TOP_P = 0.9           # æ ¸é‡‡æ ·ï¼ˆ0.0-1.0ï¼‰
REPETITION_PENALTY = 1.2  # é‡å¤æƒ©ç½š
SYSTEM_PROMPT = "ä½ æ˜¯ä¸€ä¸ªåä¸ºæ²é›ªçš„AIå¥³å­©å­"  # è§’è‰²è®¾å®šï¼ˆå¯ä¿®æ”¹ï¼‰
# ======================================

class QwenStoppingCriteria(StoppingCriteria):
    """è‡ªå®šä¹‰åœæ­¢æ¡ä»¶ï¼šæ£€æµ‹ <|im_end|> æ ‡è®°"""
    def __init__(self, stop_token_id):
        self.stop_token_id = stop_token_id

    def __call__(self, input_ids, scores, **kwargs):
        # æ£€æŸ¥æœ€åç”Ÿæˆçš„ token æ˜¯å¦æ˜¯ <|im_end|>
        return input_ids[0][-1] == self.stop_token_id

def load_model(model_dir):
    """åŠ è½½å¾®è°ƒåçš„æ¨¡å‹å’Œ tokenizer"""
    print(colored("ğŸ” æ­£åœ¨åŠ è½½æ¨¡å‹...", "yellow"))
    
    if not os.path.exists(model_dir):
        print(colored(f"âŒ é”™è¯¯ï¼šæ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}", "red"))
        print(colored("è¯·æ£€æŸ¥ MODEL_DIR é…ç½®æ˜¯å¦æ­£ç¡®", "red"))
        sys.exit(1)
    
    try:
        tokenizer = AutoTokenizer.from_pretrained(
            model_dir,
            trust_remote_code=True,
            padding_side="right"
        )
        
        # ç¡®ä¿ pad_token å­˜åœ¨
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        
        model = AutoModelForCausalLM.from_pretrained(
            model_dir,
            device_map="auto",
            trust_remote_code=True
        )
        
        # è·å– <|im_end|> çš„ token ID
        im_end_id = tokenizer.encode("<|im_end|>", add_special_tokens=False)[0]
        
        print(colored(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ! è®¾å¤‡: {next(model.parameters()).device}", "green"))
        return tokenizer, model, im_end_id
    
    except Exception as e:
        print(colored(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}", "red"))
        print(colored("å¯èƒ½åŸå› ï¼š", "red"))
        print(colored("1. æ¨¡å‹ç›®å½•ä¸åŒ…å«æœ‰æ•ˆçš„å¾®è°ƒæ¨¡å‹", "red"))
        print(colored("2. ç¼ºå°‘å¿…è¦çš„ä¾èµ–åº“", "red"))
        print(colored("3. æ˜¾å­˜ä¸è¶³", "red"))
        sys.exit(1)

def format_chat_history(chat_history):
    """å°†å¯¹è¯å†å²æ ¼å¼åŒ–ä¸º Qwen æ‰€éœ€æ ¼å¼"""
    formatted = f"<|im_start|>system\n{SYSTEM_PROMPT}<|im_end|>\n"
    
    for role, message in chat_history:
        formatted += f"<|im_start|>{role}\n{message}<|im_end|>\n"
    
    formatted += "<|im_start|>assistant\n"
    return formatted

def generate_response(pipe, chat_history, im_end_id):
    """ç”Ÿæˆæ¨¡å‹å›å¤"""
    # æ„å»ºè¾“å…¥
    prompt = format_chat_history(chat_history)
    
    # ç”Ÿæˆé…ç½®
    generation_kwargs = {
        "max_new_tokens": MAX_NEW_TOKENS,
        "temperature": TEMPERATURE,
        "top_p": TOP_P,
        "do_sample": True,
        "repetition_penalty": REPETITION_PENALTY,
        "pad_token_id": pipe.tokenizer.eos_token_id,
        "stopping_criteria": StoppingCriteriaList([QwenStoppingCriteria(im_end_id)]),
    }
    
    # ç”Ÿæˆå›å¤
    start_time = time.time()
    outputs = pipe(
        prompt,
        **generation_kwargs
    )
    response_time = time.time() - start_time
    
    # æå– assistant å›å¤ï¼ˆå»é™¤ prompt å’Œ <|im_end|>ï¼‰
    full_response = outputs[0]['generated_text']
    assistant_response = full_response[len(prompt):].replace("<|im_end|>", "").strip()
    
    # æ‰“å°æ€§èƒ½ä¿¡æ¯
    token_count = len(pipe.tokenizer.encode(assistant_response))
    print(colored(f"\nâ±ï¸  ç”Ÿæˆ {token_count} ä¸ª tokens | è€—æ—¶: {response_time:.2f} ç§’", "cyan"))
    
    return assistant_response

def print_header():
    """æ‰“å°æ¬¢è¿å¤´éƒ¨"""
    print(colored("="*50, "blue"))
    print(colored("âœ¨ æ²é›ª AI å¯¹è¯ç³»ç»Ÿ âœ¨", "magenta", attrs=["bold"]))
    print(colored("="*50, "blue"))
    print(colored("è§’è‰²è®¾å®š:", "yellow"), SYSTEM_PROMPT)
    print(colored("è¾“å…¥ 'exit' é€€å‡º, 'clear' æ¸…ç©ºå¯¹è¯å†å²", "cyan"))
    print(colored("="*50, "blue") + "\n")

def main():
    # æ£€æŸ¥ä¾èµ–
    try:
        import termcolor
    except ImportError:
        print(colored("âš ï¸ è¯·å…ˆå®‰è£… termcolor: pip install termcolor", "yellow"))
        sys.exit(1)
    
    # åŠ è½½æ¨¡å‹
    tokenizer, model, im_end_id = load_model(MODEL_DIR)
    
    # åˆ›å»º pipeline
    pipe = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        device_map="auto"
    )
    
    # åˆå§‹åŒ–å¯¹è¯å†å²
    chat_history = []
    
    # æ‰“å°æ¬¢è¿ä¿¡æ¯
    print_header()
    
    # å¯¹è¯ä¸»å¾ªç¯
    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            user_input = input(colored("ğŸ‘¤ ä½ : ", "green")).strip()
            
            # å¤„ç†ç‰¹æ®Šå‘½ä»¤
            if user_input.lower() == 'exit':
                print(colored("\nğŸ‘‹ å†è§ï¼å¸Œæœ›ä¸‹æ¬¡è¿˜èƒ½å’Œä½ èŠå¤©ï½", "magenta"))
                break
            elif user_input.lower() == 'clear':
                chat_history = []
                print(colored("\nğŸ§¹ å¯¹è¯å†å²å·²æ¸…ç©º", "yellow"))
                continue
            elif not user_input:
                continue
            
            # æ·»åŠ åˆ°å¯¹è¯å†å²
            chat_history.append(("user", user_input))
            
            # ç”Ÿæˆå›å¤
            print(colored("ğŸ¤– æ²é›ª:", "blue"), end=" ", flush=True)
            response = generate_response(pipe, chat_history, im_end_id)
            
            # æ˜¾ç¤ºå›å¤ï¼ˆé€å­—æ‰“å°æ•ˆæœï¼‰
            for char in response:
                print(char, end="", flush=True)
                time.sleep(0.01)
            print("\n")
            
            # ä¿å­˜åˆ°å¯¹è¯å†å²
            chat_history.append(("assistant", response))
            
        except KeyboardInterrupt:
            print("\n" + colored("\nâš ï¸ æŒ‰ä¸‹ Ctrl+C ä¸¤æ¬¡å¯å¼ºåˆ¶é€€å‡º", "yellow"))
        except Exception as e:
            print(colored(f"\nâŒ å¯¹è¯å‡ºé”™: {str(e)}", "red"))
            print(colored("å°è¯•æ¸…ç©ºå¯¹è¯å†å²æˆ–é‡å¯", "red"))

if __name__ == "__main__":
    main()